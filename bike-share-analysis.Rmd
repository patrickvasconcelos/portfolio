---
title: "How Does a Bike-Share Navigate Speedy Success?"
output:
  html_document:
    toc: yes
    toc_float: yes
---

This is a capstone project of the [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics), which I have been doing in the last few months, and the goal is to put all the concepts learned in it into practice, without further adoâ€¦

## Context

I am a junior data analyst working in Cyclist, a company who launched a successful bike-share offering, and nowadays the fleet of 5.824 bicycles that are geo-tracked and locked into a network of 692 stations across Chicago.
The company have three price plans, allowing the customers to use a single-ride pass, a full-day pass or an annual membership. Internally, we refer to customers with the two first price plans as casual riders, and the ones with the annual membership as Cyclistic members.

Financial analysts concluded that the Cyclistic members are much more profitable than casual riders, and with that information, the director of marketing believes that a campaign focused on the casual riders, to convert them into Cyclistic members is the key to future growth. To design this marketing strategies, we need to understand the differ between these two customers, why the casual riders would by an annual membership, and how digital media could affect our marketing tactics. Our teams are interested in analyzing the Cyclistic historical bike trip data to identify trends.

I am responsible for one answer: How do annual members and casual riders use Cyclistic bikes differently?

## Cyclistic Historical Bike-Share Data

Our historical data is in this [link](https://divvy-tripdata.s3.amazonaws.com/index.html), under this [license](https://ride.divvybikes.com/data-license-agreement). They are in 12 CSVs containing details of the bike trips for each month of 2021, and the information is in the following way:

| Column Name        | Description                                                                                |
| ------------------ | ------------------------------------------------------------------------------------------ |
| ride_id            | Code representing the ride                                                                 |
| rideable_type      | Type of bike used in the ride, it can be _electric_bike_, _classic_bike_ or  _docked_bike_ |
| started_at         | Date and time the ride started                                                             |
| ended_at           | Date and time the ride ended                                                               |
| start_station_name | Start station's name                                                                       |
| start_station_id   | Code of start station                                                                      |
| end_station_name   | End station's name                                                                         |
| end_station_id     | Code of end station                                                                        |
| start_lat          | Start latitude                                                                             |
| start_lng          | Start longitude                                                                            |
| end_lat            | End latitude                                                                               |
| end_lng            | End longitude                                                                              |
| member_casual      | Customer classification, it can be _member_ or _casual_                                    |

The data are in local folder named `bike-share-data`, following the name convention of `{yyyy}{mm}-divvy-tripdata.csv`.

> Disclaimer: The data is from [Divvy Bikes](https://ride.divvybikes.com/), an actual bike-sharing service in Chicago.

There are issues with the data such as missing values and metrics that we can infer from the database. I present the data cleaning and transformation steps in the next section.

## The Data Cleaning Process

After acquiring and understand the data of the rides, the following step is to clean and infer other information from the data that we have. Because the data is too large (more than five million rides within a year), the tools we use to the analysis is the R language, which will allow us to document a cleaning and manipulation process and generate data viz in the next steps.

```{r setup enviroment, include = FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)
Sys.setlocale(category = "LC_ALL", locale = "English")
devtools::install_github('bbc/bbplot')

if(!require(pacman))install.packages("pacman")

pacman::p_load('dplyr', 'tidyr', 'gapminder',
               'ggplot2',  'ggalt',
               'forcats', 'R.utils', 'png', 
               'grid', 'ggpubr', 'scales',
               'bbplot')
```


### Importing the data

To import the data, we use the command in R:

```{r importing data}
bike_2101 <- read.csv(file = 'bike-share-data/202101-divvy-tripdata.csv')
bike_2102 <- read.csv(file = 'bike-share-data/202102-divvy-tripdata.csv')
bike_2103 <- read.csv(file = 'bike-share-data/202103-divvy-tripdata.csv')
bike_2104 <- read.csv(file = 'bike-share-data/202104-divvy-tripdata.csv')
bike_2105 <- read.csv(file = 'bike-share-data/202105-divvy-tripdata.csv')
bike_2106 <- read.csv(file = 'bike-share-data/202106-divvy-tripdata.csv')
bike_2107 <- read.csv(file = 'bike-share-data/202107-divvy-tripdata.csv')
bike_2108 <- read.csv(file = 'bike-share-data/202108-divvy-tripdata.csv')
bike_2109 <- read.csv(file = 'bike-share-data/202109-divvy-tripdata.csv')
bike_2110 <- read.csv(file = 'bike-share-data/202110-divvy-tripdata.csv')
bike_2111 <- read.csv(file = 'bike-share-data/202111-divvy-tripdata.csv')
bike_2112 <- read.csv(file = 'bike-share-data/202112-divvy-tripdata.csv')
```

### Verifying the data

The next step is to verify the data, and for that we will use the following commands.

To list the columns in the database:

```{r list columns, echo=FALSE, message=FALSE}
colnames(bike_2101)
colnames(bike_2102)
colnames(bike_2103)
colnames(bike_2104)
colnames(bike_2105)
colnames(bike_2106)
colnames(bike_2107)
colnames(bike_2108)
colnames(bike_2109)
colnames(bike_2110)
colnames(bike_2111)
colnames(bike_2112)

```

Since all CSVs have the same columns, we can concatenate then:

```{r agregating data, warning = FALSE}
bike_data <- rbind(bike_2101, bike_2102, bike_2103, bike_2104,
                   bike_2105, bike_2106, bike_2107, bike_2108,
                   bike_2109, bike_2110, bike_2111, bike_2112)
rm(bike_2101, bike_2102, bike_2103, bike_2104,
   bike_2105, bike_2106, bike_2107, bike_2108,
   bike_2109, bike_2110, bike_2111, bike_2112)

```


To overview the data and look for missing values:

```{r verify data types and missing values}
summary(bike_data)
```
Here we can see that the `end_lat` and `end_lng` have missing values, but for our analysis we do not need this information, so we can remove it:

```{r removing columns}
bike_data <- bike_data %>% select(-c("start_lat", "start_lng", "end_lat", "end_lng"))

```


To ensure the columns have only specific values:

```{r verify itens in columns}
unique(bike_data$rideable_type)

unique(bike_data$member_casual)
```

And to ensure the time window analyzed is accurate:

```{r verify range dates}
min(bike_data$started_at)
max(bike_data$started_at)
```

### Transforming the data

We can transform then to levels to work more efficient:

```{r convert string to factor}
bike_data$rideable_type <- factor(bike_data$rideable_type)
bike_data$member_casual <- factor(bike_data$member_casual)
```

Since the number of stations is over than six hundred, we can keep it as strings.

Calculating duration of rides:

```{r rides duration}
bike_data$ride_length <- difftime(bike_data$ended_at, bike_data$started_at, units="mins")
```
And to convert to numeric:

```{r convert ride_length to numeric}
bike_data$ride_length <- as.numeric(as.character(bike_data$ride_length))
```

Removing rides below one minute, because it's potentially false starts or users trying to re-dock a bike to ensure it was secure:

```{r remove negative ride length}

bike_data <- bike_data %>% filter(ride_length >= 1 & !rideable_type == 'docked_bike')

```


We also extract information of dates:

```{r extract date info}
bike_data$date <- as.Date(bike_data$started_at)
bike_data$month <- format(as.Date(bike_data$date), "%b")
bike_data$day <- format(as.Date(bike_data$date), "%d")
bike_data$year <- format(as.Date(bike_data$date), "%Y")
bike_data$day_of_week <- format(as.Date(bike_data$date), "%a")

```

To make our analysis easier, we must ordinate the month and the days of week:

```{r}
bike_data$month <- ordered(bike_data$month, levels=c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
bike_data$day_of_week <- ordered(bike_data$day_of_week, levels=c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"))

```


## Analysis of Our Rides

With our dataset ready to be analyzed, we started with an aggregation of all rides:

```{r summarize rides, warning=FALSE, message=FALSE}
sum_rides <- bike_data %>%
  group_by() %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length))

knitr::kable(sum_rides, "pipe")
```

To understand who the customer differs, we need to compare then:

```{r rides per type user, warning=FALSE, message=FALSE}
rides_per_user <- bike_data %>%
  group_by(member_casual) %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length)) %>% 
  arrange(member_casual)

knitr::kable(rides_per_user, "pipe")
```

Now looking for patterns monthly:

```{r rides per type user and month, warning=FALSE, message=FALSE}
rides_per_user_month <- bike_data %>%
  group_by(member_casual, month) %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length)) %>% 
  arrange(month, member_casual)

knitr::kable(rides_per_user_month, "pipe")
```

Also, we look for patterns in the days of week:

```{r rides per type user and weekday, warning=FALSE, message=FALSE}
rides_per_user_weekday <- bike_data %>%
  group_by(member_casual, day_of_week) %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length)) %>% 
  arrange(day_of_week, member_casual)

knitr::kable(rides_per_user_weekday, "pipe")
```

We can search for trends of use of our two types of bikes, so let us generate this base:

```{r trends in types, warning=FALSE, message=FALSE}
rides_per_user_and_type <- bike_data %>%
  group_by(member_casual, rideable_type) %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length)) %>% 
  arrange(member_casual)

knitr::kable(rides_per_user_and_type, "pipe")
```
Also, we can analyze the data mothly:

```{r trends in types on months, warning=FALSE, message=FALSE}

rides_per_user_and_type_month <- bike_data %>%
  group_by(member_casual, rideable_type, month) %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length)) %>% 
  arrange(month, member_casual, rideable_type)


knitr::kable(rides_per_user_and_type_month, "pipe")
```
And inside a week:

```{r trends in types on days of week, warning=FALSE, message=FALSE}

rides_per_user_and_type_weekday <- bike_data %>%
  group_by(member_casual, rideable_type, day_of_week) %>%
  summarise(number_of_rides=n(),
            average_duration=mean(ride_length),
            shortest_ride=min(ride_length),
            longest_ride=max(ride_length)) %>% 
  arrange(day_of_week, member_casual, rideable_type)

knitr::kable(rides_per_user_and_type_weekday, "pipe")

```

Based on type of bike used, the customers present the same behavior.

After analyzing the database, we will create data visualizations to communicate our findings.

## Share our Findings

After performed our analysis, we will develop data visualizations to communicate our findings to the executive team. To do that, we will need to be concise and precise on our decisions to what use on the presentation.

Beginning with a chart to compare the total number of rides made for each type of customer:

```{r general comparing, warning=FALSE}
rides_per_user %>% 
ggplot(aes(x=member_casual, y = number_of_rides, fill=member_casual)) +
  geom_bar(stat="identity", position="identity") +
  scale_fill_manual(values = c("#1a3068", "#325dcc")) +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  bbc_style() +
  labs(title="Cyclistic members ride more",
       subtitle = "In 2021 was over then 5 million rides"
      ) +
  scale_y_continuous(limits=c(0,3200000),
                   breaks = seq(0, 3000000, by = 1000000),
                   labels = c("0","1 M", "2 M", "3 M")) +
  scale_x_discrete(labels = c("Casual riders", "Cyclistic members")) +
  theme(legend.position = "none")
```

When we look at the month behavior:

```{r monthly data, warning=FALSE}
rides_per_user_month %>%
  ggplot(aes(x = month, y = number_of_rides, group = member_casual, color=member_casual
             )) +
   geom_line(size=1)  +
  scale_color_manual(values = c("#1a3068", "#325dcc")) +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  bbc_style() +
  labs(title="Seasonal trend",
       subtitle = "But the customers behave similarly"
      ) +
  scale_y_continuous(limits=c(0,420000),
                   breaks = seq(0, 400000, by = 100000),
                   labels = c("0","100 K", "200 K", "300 K", "400 K")) +
  theme(legend.position = "none") +
  geom_label(aes(x = 8, y = 80000, label = "Casual riders"), 
             hjust = 0, 
             vjust = 0.5, 
             colour = "#1a3068", 
             fill = "white", 
             label.size = NA,
             size = 5) +
  geom_label(aes(x = 8, y = 410000, label = "Cyclistic members"), 
             hjust = 0, 
             vjust = 0.5, 
             colour = "#325dcc",
             fill = "white",
             label.size = NA,
             size = 5)
  
```

Now, looking to the week data:


```{r weekly data, warning=FALSE}
rides_per_user_weekday %>%
  ggplot(aes(x = day_of_week, y = number_of_rides, group = member_casual, color=member_casual
             )) +
   geom_line(size=1)  +
  scale_color_manual(values = c("#1a3068", "#325dcc")) +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  bbc_style() +
  labs(title="Be casual on Weekends",
       subtitle = "Casual rides increase on weekends"
      ) +
  scale_y_continuous(limits=c(0,550000),
                   breaks = seq(0, 400000, by = 100000),
                   labels = c("0","100 K", "200 K", "300 K", "400 K")) +
  theme(legend.position = "none") +
  geom_label(aes(x = 5, y = 200000, label = "Casual riders"), 
             hjust = 0, 
             vjust = 0.5, 
             colour = "#1a3068", 
             fill = "white", 
             label.size = NA,
             size = 5) +
  geom_label(aes(x = 5, y = 500000, label = "Cyclistic members"), 
             hjust = 0, 
             vjust = 0.5, 
             colour = "#325dcc",
             fill = "white",
             label.size = NA,
             size = 5)
```

we can see a pattern, on weekends casual riders usually make more rides.

Analyzing the duration of rides:

```{r average per day of week, warning=FALSE}
rides_per_user_weekday %>%
  ggplot(aes(x = day_of_week, y = average_duration, group = member_casual, color=member_casual
             )) +
   geom_line(size=1)  +
  scale_color_manual(values = c("#1a3068", "#325dcc")) +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  bbc_style() +
  labs(title="Casually riding more",
       subtitle = "On average, casual riders ride longer"
      ) +
  scale_y_continuous(limits=c(0,30),
                   breaks = seq(0, 30, by = 10),
                   labels = c("0","10", "20", "30 min")) +
  theme(legend.position = "none") +
  geom_label(aes(x = 5, y = 30, label = "Casual riders"), 
             hjust = 0, 
             vjust = 0.5, 
             colour = "#1a3068", 
             fill = "white", 
             label.size = NA,
             size = 5) +
  geom_label(aes(x = 5, y = 10, label = "Cyclistic members"), 
             hjust = 0, 
             vjust = 0.5, 
             colour = "#325dcc",
             fill = "white",
             label.size = NA,
             size = 5)
```

We can see that the Cyclistic members make the shortest rides.



## Suggestion of New Plans

Our results suggests that the casual riders take more rides on weekends, and they also do the longer rides, so we can give three recommendations:

- Create new annual plans with more flexibility, such as plans valid only on the weekends.
- Create new fidelity plan, so customer who rides longer have discount when he is a Cyclistic member.
- Create a month plan, to attend the high pic of rides in the middle of the year.

As further analysis we can use data from the customers, such as job occupation and how they use our bikes, to understand why the use on weekend is so high.
